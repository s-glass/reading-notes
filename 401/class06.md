# 401 class 06 notes

**Why this matters**: This information matters because random module, risk analysis, test coverage, and more info on Big O notation will all help with the assignments we have coming up this week.

------------------------------------


**1. How can the random module be utilized in Python to generate random numbers or make selections from a list, and what are some common functions available within the module?**

By using provided functions that come with the random module, you can generate random values and make random selections. Common functions are `randint()`, `random()`, `choice()`, `randrange()`, and `shuffle()`.

**2. In the context of software development, what is risk analysis, and what are the key steps involved in conducting a risk analysis for a software project?**

Software risk analysis involves identifying risks and potential problem areas in applications and prioritizing them for testing.

Key steps in risk assessment are:

(1) Early forecast of unwanted situation in your project

(2) Estimating potential loss of such situation

(3) Making decision to deal with such situation

(4) Avoid the future consequences


[Source](https://www.lambdatest.com/learning-hub/software-risk-analysis)
[Source](https://www.edureka.co/blog/risk-analysis-in-software-testing/)


**3. What is test coverage and why is it an important (or potentially misleading) metric in software testing?**

Test coverage, aka code coverage, is a useful tool for finding untested parts of a codebase.

It is a potentially misleading metric in software testing because "If you make a certain level of coverage a target, people will try to attain it. The trouble is that high coverage numbers are too easy to reach with low quality testing. At the most absurd level you have AssertionFreeTesting. But even without that you get lots of tests looking for things that rarely go wrong distracting you from testing the things that really matter."

[Source](https://martinfowler.com/bliki/TestCoverage.html)


**4. What is Big O notation, and how is it used to describe the performance of an algorithm? Give an example of an everyday task (not software related) that demonstrates O(n) time complexity.**

Big O notation is an equation that descibes how the runtime scales with respect to some input variables.

It's used to describe the performance of an algorithm by explaining how efficient an algorithm is, how it scales or increases / decreases with values like (n), and effectively, how long it will take to process a given set of data or code.

O(n) time complexity could be demonstrated by mowing the lawn, the time it takes to mow will scale linearly depending on how much grass (n) there is to mow.


[Source](https://www.youtube.com/watch?v=v4cd1O4zkGw) 

------------------------------------
### Things I Want To Know More About:
Nothing at the moment!